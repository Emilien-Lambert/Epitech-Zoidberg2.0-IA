{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"zoidberg.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"T7l0L_cHmU-I"},"source":["> `Matthieu ALCARO, Emilien LAMBERT, Antonio VALLERA, Leo MARCEL, Fares QEDIRA`\n","---\n","\n","# **ZOIDBERG 2.0**\n","In this notebook, we will use 3 datasets of lungs x-ray images to help doctors detecting if the patient has pneumonia.\n","\n","In order do this we will first classify our datasets as they are different types of images, some are in R.G.B (3D) and some in B&W (2D).\n","Then transform them to determine the lungs disease.\n","\n"," Regarding our precedent work on MNIST, which was about recognize different handwritten digits, we integrated our MNIST logic inside this 'zoidberg 2.0 project'\n","\n","\n","## 1. **Installation of external packages**\n","\n","Some external packages and modules are needed to make the all processwork,    like :\n","\n",">- `matplotlib` *(Creates visualizations in Python)*\n","    - `matimage` *(image loading, rescaling and display operations)*\n","    - `pylot` *(functions to manipulate elements of a figure)*\n","- `numpy` *(extended mathematical functions)*\n","- `graphviz` *(create graph objects)*\n","- `sklearn` *(provides learning algorithms)*\n","    - `metrics`\n","    - `decomposition`\n","    - `kernel_approximation`\n","    - `neural_network`\n","    - `neighbors`\n","    - `naive_bayes`\n","    - `tree`\n","    - `ensemble`\n","    - `model_selection`\n","- `math` *(basic math functions)*\n","- `mnist` *(database of handwritten digits)*\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ENR1GQ7tj-JI","executionInfo":{"status":"ok","timestamp":1620301620077,"user_tz":-120,"elapsed":3864,"user":{"displayName":"Fares QEDIRA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjeU6tNiPuMVSkH52U1-5VMYLH9jjIkHjNYSQViSg=s64","userId":"05223290990673471170"}},"outputId":"7dcef664-96e7-4fed-a102-f9bfbdb4e9fd"},"source":["# get dataset files from google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!cd \"/content/drive/My Drive/zoidberg\"\n","\n","#installation of dependencies\n","!pip install sklearn matplotlib numpy graphviz python-mnist python-math\n","\n","import os\n","import re\n","import time\n","\n","#external packages\n","import matplotlib.image as mpimg\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import graphviz\n","\n","from sklearn import svm, metrics, tree\n","from sklearn.metrics import accuracy_score\n","from sklearn.decomposition import PCA\n","from sklearn.kernel_approximation import Nystroem\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n","from sklearn.model_selection import cross_val_score\n","from math import sqrt\n","\n","from math import sqrt\n","from mnist import MNIST\n","\n","from datetime import datetime, timedelta"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (0.10.1)\n","Requirement already satisfied: python-mnist in /usr/local/lib/python3.7/dist-packages (0.7)\n","Requirement already satisfied: python-math in /usr/local/lib/python3.7/dist-packages (0.0.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jbnGQVvuyY38"},"source":["# 2. **Dataset Importing**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sJKr8VAQGhsv"},"source":["This part of the code is only used to import the dataset in our code, dataset located in the folder ./mnist and \"data ia sorted\".\n","\n","`img_train` (folder \"data ia sorted\"/all/train/) allows our algorithm to learn, it is then that it will be able to make its tests, one by one, on the data in `img_test` (folder \"data ia sorted\"/all/test/).\n"]},{"cell_type":"code","metadata":{"id":"CmDZ3SV131hy"},"source":["def data_formatting(path):\n","    # List all name of images file in a table\n","    images_name = [f for f in os.listdir(path) if re.match(r'.*\\.jpeg', f)]\n","\n","    # Create table of label and image path\n","    labels = []\n","    images_path = []\n","    counter = 0\n","\n","    # Create a table of reformatted images\n","    images = []\n","    good_images = []\n","    bad_images = []\n","\n","    for image_name in images_name:\n","        img = mpimg.imread(path + image_name)\n","        if img.ndim == 2:\n","            cropped = crop(img, 200)\n","            cropped = cropped / 255\n","            cropped = np.reshape(cropped, 40000)\n","            good_images.append(cropped)\n","            if \"virus\" in image_name:\n","                labels.append(\"virus\")\n","            elif \"bacteria\" in image_name:\n","                labels.append(\"bacteria\")\n","            else:\n","                labels.append(\"normal\")\n","        elif img.ndim == 3:\n","            bad_images.append(img)\n","\n","    #         # TODO : probl√®me de RGB\n","\n","    # np_img = np.array(img_table)\n","    # np_label = np.array(label_table)\n","    # return np_img, np_label\n","\n","    # for image_name in images_name:\n","    #     counter += 1\n","    #     if \"virus\" in image_name:\n","    #         labels.append(\"virus\")\n","    #         images_path.append(path + image_name)\n","    #     elif \"bacteria\" in image_name:\n","    #         labels.append(\"bacteria\")\n","    #         images_path.append(path + image_name)\n","    #     else:\n","    #         labels.append(\"normal\")\n","    #         images_path.append(path + image_name)\n","\n","    # for i in range(len(images_path)):\n","    #     images.append(mpimg.imread(images_path[i]))\n","    #     if images[i].ndim == 2:\n","    #         good_images.append(images[i])\n","    #     elif images[i].ndim == 3:\n","    #         bad_images.append(images[i])\n","    #     i -= 1\n","\n","    return good_images, labels\n","\n","\n","def load_dataset(type_data):\n","    if type_data == 'mnist':\n","        mn_data = MNIST('./mnist/')\n","        images_training, labels_training = mn_data.load_training()\n","        images_testing, labels_testing = mn_data.load_testing()\n","        data = {\n","            'np_images_training': np.array(images_training),\n","            'np_labels_training': np.array(labels_training),\n","            'np_images_testing': np.array(images_testing),\n","            'np_labels_testing': np.array(labels_testing)\n","        }\n","        return data\n","\n","    elif type_data == 'pneumonia':\n","\n","        train_images, train_labels = data_formatting(\"data ia sorted/all/train/\")\n","        test_images, test_labels = data_formatting(\"data ia sorted/all/test/\")\n","        validation_images, validation_labels = data_formatting(\"data ia sorted/all/validation/\")\n","\n","        # plt.imshow(train_images[0], cmap=plt.get_cmap(\"gray\"))\n","        # plt.show()\n","\n","        data = {\n","            'np_images_training': np.array(train_images),\n","            'np_labels_training': np.array(train_labels),\n","            'np_images_testing': np.array(test_images),\n","            'np_labels_testing': np.array(test_labels),\n","            \"np_images_validation\": np.array(validation_images),\n","            \"np_labels_validation\": np.array(validation_labels),\n","        }\n","        return data\n","\n","\n","def main():\n","    print(\"--------------- START LOAD_DATASET ---------------\")\n","    start_time = time.time()\n","    data = load_dataset('pneumonia')\n","    print(\"--------------- FINISH : %s SECONDS ---------------\" % (time.time() - start_time))\n","\n","    models = Sklearn(data)\n","\n","    # visualize = Statistics()\n","    # visualize.pca_3d(models.np_images_training, models.np_labels_training)\n","\n","    # Les transform\n","    print(\"--------------- START TRANSFORM ---------------\")\n","    # start_time = time.time()\n","    # transform = Transformation()\n","    # train_data_transform = transform.nystroem(models.np_images_training)\n","    # test_data_transform = transform.nystroem(models.np_images_testing)\n","    # models.np_images_training = train_data_transform\n","    # models.np_images_testing = test_data_transform\n","    print(\"--------------- FINISH : %s SECONDS ---------------\" % (time.time() - start_time))\n","\n","    # Les algo\n","    print(\"--------------- START TRAINING ---------------\")\n","    start_time = time.time()\n","    # models.svc()\n","    # print(models.svc_linear())\n","    # my_model = models.mlp_classifier()\n","\n","    # models.prediction_knn()\n","    # models.naive_bayes()\n","    # models.decision_tree_classifier(5)\n","    models.random_tree_forest(100, 5)\n","    # models.extremely_randomized_trees(100, 10)\n","\n","    print(\"--------------- FINISH : %s SECONDS ---------------\" % (time.time() - start_time))\n","\n","    # Les stats\n","    # models.get_scores(my_model)\n","    # predictions = models.get_predictions(my_model)\n","    # models.get_matrix(my_model, predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xsGHdd4ykb_-","colab":{"base_uri":"https://localhost:8080/","height":324},"executionInfo":{"status":"error","timestamp":1620305633498,"user_tz":-120,"elapsed":969,"user":{"displayName":"Fares QEDIRA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjeU6tNiPuMVSkH52U1-5VMYLH9jjIkHjNYSQViSg=s64","userId":"05223290990673471170"}},"outputId":"e531ebfa-b00f-40cb-a9bf-d71d2effbf3f"},"source":["main()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--------------- START LOAD_DATASET ---------------\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-46-bd26517efc90>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------- START LOAD_DATASET ---------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pneumonia'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------- FINISH : %s SECONDS ---------------\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-46-bd26517efc90>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(type_data)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_data\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pneumonia'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_formatting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data ia sorted/all/train/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_formatting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data ia sorted/all/test/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mvalidation_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_formatting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data ia sorted/all/validation/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-46-bd26517efc90>\u001b[0m in \u001b[0;36mdata_formatting\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbad_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'images_name' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"6stVhr80IuSU"},"source":["# 3. **Algorithme**"]}]}